{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove newline character ('\\n') and HTML tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Remove newline character\n",
    "    text = text.replace('\\n', '')\n",
    "\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process XML strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Invention Title\n",
    "def get_invention_title(text):\n",
    "    xml = ET.fromstring(text)\n",
    "    invention_title = clean_text(xml.text)\n",
    "    return invention_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Abstract\n",
    "\n",
    "# Extract sibling <p> tags' text\n",
    "def get_sibling_tags(element):\n",
    "    text = element.text or ''\n",
    "    for child in element:\n",
    "        text += ET.tostring(child, encoding='unicode', method='text')\n",
    "        if child.tail:\n",
    "            text += child.tail\n",
    "    return text\n",
    "\n",
    "# Concatenate sibling <p> tags and return result\n",
    "def get_abstract(text):\n",
    "    p_tag_content = \"\"\n",
    "    xml = ET.fromstring(text)\n",
    "    p_tags = xml.findall('.//p')\n",
    "    for p in p_tags:\n",
    "        p_tag_content += get_sibling_tags(p)\n",
    "\n",
    "    abstract = clean_text(p_tag_content)\n",
    "\n",
    "    return abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract <claims> text\n",
    "def get_claims(claims_text):\n",
    "    text = \"\"\n",
    "    xml = ET.fromstring(claims_text)\n",
    "    claims = xml.findall('.//claim-text')\n",
    "\n",
    "    # extract claims text out of xml\n",
    "    for claim in claims:\n",
    "        text += get_sibling_tags(claim) \n",
    "    result = clean_text(text)\n",
    "    \n",
    "    return result "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process JSON Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON data and return [{ucid, title, abstract, claims}]\n",
    "def process_json(json_data_dir):\n",
    "\n",
    "    with open(json_data_dir, \"r\") as json_file:\n",
    "        \n",
    "        lines = json_file.readlines() # each line contains one json object as str\n",
    "        \n",
    "        json_list = [] # a list of dictonaries, where each dictionary is a json object\n",
    "\n",
    "        for l in lines:\n",
    "            data = json.loads(l) # load json object\n",
    "\n",
    "            ucid = data['ucid']\n",
    "    \n",
    "            invention_title_xml = data['invention_title']['text']\n",
    "            abstract_xml = data['abstract']['text']\n",
    "            claims_xml = data['claims']['text']\n",
    "\n",
    "            title = get_invention_title(invention_title_xml)\n",
    "            abstract = get_abstract(abstract_xml)\n",
    "            claims = get_claims(claims_xml)\n",
    "        \n",
    "            json_list.append({'ucid':ucid,'title':title, 'abstract':abstract, 'claims':claims})\n",
    "            \n",
    "    \n",
    "    return json_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write JSON list to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to csv file\n",
    "def write2csv(json_list, output_dir):\n",
    "    with open(output_dir, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        headers = ['ucid','title','abstract','claims']\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=headers)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(json_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Invoke the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect json data from json file file directory\n",
    "# json_data = process_json(json_data_dir='./data/case_data.json')\n",
    "\n",
    "# write the json data to a csv file \n",
    "# write2csv(json_list=json_data, output_dir='./output_data/case_data_2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
